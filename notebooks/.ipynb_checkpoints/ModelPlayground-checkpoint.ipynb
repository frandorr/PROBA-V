{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "sys.path.insert(0, '..')\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger('__name__')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Nadam\n",
    "\n",
    "from modelsTF import *\n",
    "from loss import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (52563, 32, 32, 9, 1) --------> Output shape: (52563, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "CLEAN_DATA_DIR = '/home/mark/DataBank/PROBA-V-CHKPT/trimmedPatchesDir'\n",
    "band = 'NIR'\n",
    "X_train = np.load(os.path.join(CLEAN_DATA_DIR, f'TRAINpatchesLR_{band}.npy'), allow_pickle=True)\n",
    "y_train = np.load(os.path.join(CLEAN_DATA_DIR, f'TRAINpatchesHR_{band}.npy'), allow_pickle=True)\n",
    "\n",
    "X = X_train.transpose((0, 3, 4, 2, 1))\n",
    "y = y_train.transpose((0, 3, 4, 2, 1)).squeeze(3)\n",
    "print(f'Input shape: {X.shape} --------> Output shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(0, 1400, (100, 32, 32, 9, 1))\n",
    "y = np.random.randint(0, 1400, (100, 96, 96, 1))\n",
    "y_mask = np.random.randint(0, 2, (100, 96, 96, 1)).astype(np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 19:51:17,674 - From /home/mark/.local/lib/python3.6/site-packages/tensorflow_addons/layers/wrappers.py:84: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "model = WDSRConv3D(scale=3, numFilters=32, kernelSize=(3, 3, 3), numResBlocks=8,\n",
    "                expRate=8, decayRate=0.8, numImgLR=9, patchSizeLR=32, isGrayScale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a59feb1fe17a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshiftCompensatedL1Lossv3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m       \u001b[0;31m# Creates the model loss and weighted metrics sub-graphs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_weights_loss_and_weighted_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m       \u001b[0;31m# Functions for train, test and predict will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_weights_loss_and_weighted_metrics\u001b[0;34m(self, sample_weights)\u001b[0m\n\u001b[1;32m   1590\u001b[0m       \u001b[0;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m       \u001b[0;31m#                   layer losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_skip_target_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reduction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m             \u001b[0mper_sample_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m             weighted_losses = losses_utils.compute_weighted_loss(\n\u001b[1;32m   1654\u001b[0m                 \u001b[0mper_sample_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    219\u001b[0m       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n\u001b[1;32m    220\u001b[0m           y_pred, y_true)\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-310acfd8d157>\u001b[0m in \u001b[0;36mshiftCompensatedL1Lossv3\u001b[0;34m(yTrue, predPatchHR)\u001b[0m\n\u001b[1;32m     40\u001b[0m     '''\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mpatchHR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaskHR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mtheShape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatchHR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mcropSizeHeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m96\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mMAX_PIXEL_SHIFT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iterating over `tf.Tensor`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    513\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    514\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=shiftCompensatedL1Lossv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam(learning_rate=5e-4)\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                     psnr=tf.Variable(1.0),\n",
    "                                     optimizer=optimizer,\n",
    "                                     model=model)\n",
    "checkpointManager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
    "                                                   directory='models',\n",
    "                                                   max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainDataAsTFDataSet(X, y, y_mask, epochs, batchSize, bufferSize):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (X, y, y_mask)).shuffle(bufferSize, reshuffle_each_iteration=True).repeat(epochs).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "def loadValDataAsTFDataSet(X, y, y_mask, valSteps, batchSize, bufferSize):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (X, y, y_mask)).shuffle(bufferSize).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE).take(valSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val, y_train_mask, y_val_mask = train_test_split(\n",
    "        X, y, y.mask, test_size=0.7, random_state=17)\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "y_train_mask = tf.convert_to_tensor(y_train_mask, dtype=tf.float32)\n",
    "y_val_mask = tf.convert_to_tensor(y_val_mask, dtype=tf.float32)\n",
    "\n",
    "y = [y_train, y_train_mask]\n",
    "valData = [X_val, y_val, y_val_mask]\n",
    "\n",
    "# Initialize metrics\n",
    "trainLoss = Mean(name='trainLoss')\n",
    "trainPSNR = Mean(name='trainPSNR')\n",
    "testLoss = Mean(name='testLoss')\n",
    "testPSNR = Mean(name='testPSNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 19:55:51,779 - step 101/1576, loss: 5832.753, psnr: 5832.753\n",
      "2020-02-28 19:55:51,900 - step 102/1576, loss: 5837.041, psnr: 5837.041\n",
      "2020-02-28 19:55:52,012 - step 103/1576, loss: 5827.358, psnr: 5827.358\n",
      "2020-02-28 19:55:52,118 - step 104/1576, loss: 5839.522, psnr: 5839.522\n",
      "2020-02-28 19:55:52,224 - step 105/1576, loss: 5842.938, psnr: 5842.938\n",
      "2020-02-28 19:55:52,330 - step 106/1576, loss: 5846.369, psnr: 5846.369\n",
      "2020-02-28 19:55:52,436 - step 107/1576, loss: 5857.054, psnr: 5857.054\n",
      "2020-02-28 19:55:52,541 - step 108/1576, loss: 5850.004, psnr: 5850.004\n",
      "2020-02-28 19:55:52,646 - step 109/1576, loss: 5858.256, psnr: 5858.256\n",
      "2020-02-28 19:55:52,751 - step 110/1576, loss: 5864.854, psnr: 5864.854\n",
      "2020-02-28 19:55:52,855 - step 111/1576, loss: 5873.917, psnr: 5873.917\n",
      "2020-02-28 19:55:52,961 - step 112/1576, loss: 5876.588, psnr: 5876.588\n",
      "2020-02-28 19:55:53,066 - step 113/1576, loss: 5880.762, psnr: 5880.762\n",
      "2020-02-28 19:55:53,173 - step 114/1576, loss: 5892.241, psnr: 5892.241\n",
      "2020-02-28 19:55:53,284 - step 115/1576, loss: 5910.988, psnr: 5910.988\n",
      "2020-02-28 19:55:53,390 - step 116/1576, loss: 5924.735, psnr: 5924.735\n",
      "2020-02-28 19:55:53,495 - step 117/1576, loss: 5930.219, psnr: 5930.219\n",
      "2020-02-28 19:55:53,601 - step 118/1576, loss: 5917.187, psnr: 5917.187\n",
      "2020-02-28 19:55:53,705 - step 119/1576, loss: 5929.024, psnr: 5929.024\n",
      "2020-02-28 19:55:53,810 - step 120/1576, loss: 5918.327, psnr: 5918.327\n",
      "2020-02-28 19:55:53,915 - step 121/1576, loss: 5886.048, psnr: 5886.048\n",
      "2020-02-28 19:55:54,020 - step 122/1576, loss: 5886.691, psnr: 5886.691\n",
      "2020-02-28 19:55:54,126 - step 123/1576, loss: 5889.064, psnr: 5889.064\n",
      "2020-02-28 19:55:54,231 - step 124/1576, loss: 5895.993, psnr: 5895.993\n",
      "2020-02-28 19:55:54,336 - step 125/1576, loss: 5896.413, psnr: 5896.413\n",
      "2020-02-28 19:55:54,441 - step 126/1576, loss: 5911.042, psnr: 5911.042\n",
      "2020-02-28 19:55:54,545 - step 127/1576, loss: 5921.388, psnr: 5921.388\n",
      "2020-02-28 19:55:54,649 - step 128/1576, loss: 5929.761, psnr: 5929.761\n",
      "2020-02-28 19:55:54,755 - step 129/1576, loss: 5938.119, psnr: 5938.119\n",
      "2020-02-28 19:55:54,889 - step 130/1576, loss: 5929.659, psnr: 5929.659\n",
      "2020-02-28 19:55:55,025 - step 131/1576, loss: 5935.798, psnr: 5935.798\n",
      "2020-02-28 19:55:55,150 - step 132/1576, loss: 5938.246, psnr: 5938.246\n",
      "2020-02-28 19:55:55,256 - step 133/1576, loss: 5928.176, psnr: 5928.176\n",
      "2020-02-28 19:55:55,362 - step 134/1576, loss: 5926.601, psnr: 5926.601\n",
      "2020-02-28 19:55:55,469 - step 135/1576, loss: 5937.037, psnr: 5937.037\n",
      "2020-02-28 19:55:55,574 - step 136/1576, loss: 5938.052, psnr: 5938.052\n",
      "2020-02-28 19:55:55,680 - step 137/1576, loss: 5940.170, psnr: 5940.170\n",
      "2020-02-28 19:55:55,790 - step 138/1576, loss: 5942.538, psnr: 5942.538\n",
      "2020-02-28 19:55:55,895 - step 139/1576, loss: 5932.325, psnr: 5932.325\n",
      "2020-02-28 19:55:55,999 - step 140/1576, loss: 5938.319, psnr: 5938.319\n",
      "2020-02-28 19:55:56,104 - step 141/1576, loss: 5949.986, psnr: 5949.986\n",
      "2020-02-28 19:55:56,209 - step 142/1576, loss: 5949.072, psnr: 5949.072\n",
      "2020-02-28 19:55:56,314 - step 143/1576, loss: 5937.528, psnr: 5937.528\n",
      "2020-02-28 19:55:56,426 - step 144/1576, loss: 5934.831, psnr: 5934.831\n",
      "2020-02-28 19:55:56,531 - step 145/1576, loss: 5945.773, psnr: 5945.773\n",
      "2020-02-28 19:55:56,636 - step 146/1576, loss: 5951.062, psnr: 5951.062\n",
      "2020-02-28 19:55:56,741 - step 147/1576, loss: 5961.112, psnr: 5961.112\n",
      "2020-02-28 19:55:56,849 - step 148/1576, loss: 5936.530, psnr: 5936.530\n",
      "2020-02-28 19:55:56,955 - step 149/1576, loss: 5940.521, psnr: 5940.521\n",
      "2020-02-28 19:55:57,075 - step 150/1576, loss: 5934.189, psnr: 5934.189\n",
      "2020-02-28 19:55:57,211 - step 151/1576, loss: 5916.348, psnr: 5916.348\n",
      "2020-02-28 19:55:57,352 - step 152/1576, loss: 5916.019, psnr: 5916.019\n",
      "2020-02-28 19:55:57,462 - step 153/1576, loss: 5917.346, psnr: 5917.346\n",
      "2020-02-28 19:55:57,571 - step 154/1576, loss: 5923.994, psnr: 5923.994\n",
      "2020-02-28 19:55:57,679 - step 155/1576, loss: 5923.513, psnr: 5923.513\n",
      "2020-02-28 19:55:57,783 - step 156/1576, loss: 5927.124, psnr: 5927.124\n",
      "2020-02-28 19:55:57,888 - step 157/1576, loss: 5927.324, psnr: 5927.324\n",
      "2020-02-28 19:55:57,994 - step 158/1576, loss: 5928.200, psnr: 5928.200\n",
      "2020-02-28 19:55:58,099 - step 159/1576, loss: 5929.676, psnr: 5929.676\n",
      "2020-02-28 19:55:58,205 - step 160/1576, loss: 5920.154, psnr: 5920.154\n",
      "2020-02-28 19:55:58,310 - step 161/1576, loss: 5919.766, psnr: 5919.766\n",
      "2020-02-28 19:55:58,447 - step 162/1576, loss: 5923.314, psnr: 5923.314\n",
      "2020-02-28 19:55:58,582 - step 163/1576, loss: 5931.178, psnr: 5931.178\n",
      "2020-02-28 19:55:58,700 - step 164/1576, loss: 5932.218, psnr: 5932.218\n",
      "2020-02-28 19:55:58,805 - step 165/1576, loss: 5937.473, psnr: 5937.473\n",
      "2020-02-28 19:55:58,911 - step 166/1576, loss: 5928.711, psnr: 5928.711\n",
      "2020-02-28 19:55:59,016 - step 167/1576, loss: 5927.434, psnr: 5927.434\n",
      "2020-02-28 19:55:59,122 - step 168/1576, loss: 5933.608, psnr: 5933.608\n",
      "2020-02-28 19:55:59,227 - step 169/1576, loss: 5913.784, psnr: 5913.784\n",
      "2020-02-28 19:55:59,364 - step 170/1576, loss: 5910.937, psnr: 5910.937\n",
      "2020-02-28 19:55:59,499 - step 171/1576, loss: 5902.488, psnr: 5902.488\n",
      "2020-02-28 19:55:59,625 - step 172/1576, loss: 5903.511, psnr: 5903.511\n",
      "2020-02-28 19:55:59,729 - step 173/1576, loss: 5898.674, psnr: 5898.674\n",
      "2020-02-28 19:55:59,835 - step 174/1576, loss: 5903.326, psnr: 5903.326\n",
      "2020-02-28 19:55:59,940 - step 175/1576, loss: 5895.213, psnr: 5895.213\n",
      "2020-02-28 19:56:00,047 - step 176/1576, loss: 5895.459, psnr: 5895.459\n",
      "2020-02-28 19:56:00,151 - step 177/1576, loss: 5898.794, psnr: 5898.794\n",
      "2020-02-28 19:56:00,265 - step 178/1576, loss: 5900.346, psnr: 5900.346\n",
      "2020-02-28 19:56:00,399 - step 179/1576, loss: 5915.315, psnr: 5915.315\n",
      "2020-02-28 19:56:00,531 - step 180/1576, loss: 5905.705, psnr: 5905.705\n",
      "2020-02-28 19:56:00,636 - step 181/1576, loss: 5909.395, psnr: 5909.395\n",
      "2020-02-28 19:56:00,742 - step 182/1576, loss: 5903.924, psnr: 5903.924\n",
      "2020-02-28 19:56:00,847 - step 183/1576, loss: 5910.067, psnr: 5910.067\n",
      "2020-02-28 19:56:00,951 - step 184/1576, loss: 5914.332, psnr: 5914.332\n",
      "2020-02-28 19:56:01,057 - step 185/1576, loss: 5920.724, psnr: 5920.724\n",
      "2020-02-28 19:56:01,162 - step 186/1576, loss: 5920.568, psnr: 5920.568\n",
      "2020-02-28 19:56:01,266 - step 187/1576, loss: 5913.836, psnr: 5913.836\n",
      "2020-02-28 19:56:01,371 - step 188/1576, loss: 5915.165, psnr: 5915.165\n",
      "2020-02-28 19:56:01,476 - step 189/1576, loss: 5916.970, psnr: 5916.970\n",
      "2020-02-28 19:56:01,608 - step 190/1576, loss: 5915.320, psnr: 5915.320\n",
      "2020-02-28 19:56:01,745 - step 191/1576, loss: 5918.713, psnr: 5918.713\n",
      "2020-02-28 19:56:01,879 - step 192/1576, loss: 5908.969, psnr: 5908.969\n",
      "2020-02-28 19:56:01,986 - step 193/1576, loss: 5901.924, psnr: 5901.924\n",
      "2020-02-28 19:56:02,092 - step 194/1576, loss: 5896.441, psnr: 5896.441\n",
      "2020-02-28 19:56:02,198 - step 195/1576, loss: 5903.742, psnr: 5903.742\n",
      "2020-02-28 19:56:02,304 - step 196/1576, loss: 5905.744, psnr: 5905.744\n",
      "2020-02-28 19:56:02,409 - step 197/1576, loss: 5900.333, psnr: 5900.333\n",
      "2020-02-28 19:56:02,515 - step 198/1576, loss: 5899.306, psnr: 5899.306\n",
      "2020-02-28 19:56:02,620 - step 199/1576, loss: 5903.459, psnr: 5903.459\n",
      "2020-02-28 19:56:02,726 - step 200/1576, loss: 5883.204, psnr: 5883.204\n"
     ]
    },
    {
     "ename": "InaccessibleTensorError",
     "evalue": "in converted code:\n\n    <ipython-input-16-23a591338633>:89 testStep  *\n        loss = loss(patchHR, maskHR, predPatchHR)\n    ../utils/loss.py:72 shiftCompensatedL1Loss  *\n        cacheLosses = tf.stack(cacheLosses)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1165 stack\n        return gen_array_ops.pack(values, axis=axis, name=name)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py:6304 pack\n        \"Pack\", values=values, axis=axis, name=name)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py:793 _apply_op_helper\n        op_def=op_def)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py:544 create_op\n        inp = self.capture(inp)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py:603 capture\n        % (tensor, tensor.graph, self))\n\n    InaccessibleTensorError: The tensor 'Tensor(\"mul_3:0\", shape=(10, 10), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_body_106678, id=140013908497632); accessed from: FuncGraph(name=testStep, id=140014551336048).\n    \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInaccessibleTensorError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1206a8497195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointManager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                  'logs', 'models', 1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-23a591338633>\u001b[0m in \u001b[0;36mfitTrainData\u001b[0;34m(model, optimizer, metrics, lossFunc, PSNRFunc, X, y, batchSize, epochs, bufferSize, valData, valSteps, checkpoint, checkpointManager, logDir, ckptDir, saveBestOnly)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx_batch_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mask_batch_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalSet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     testStep(x_batch_val, y_batch_val, y_mask_batch_val, checkpoint,\n\u001b[0;32m---> 57\u001b[0;31m                              lossFunc, PSNRFunc, testLoss, testPSNR)\n\u001b[0m\u001b[1;32m     58\u001b[0m                 tf.summary.scalar(\n\u001b[1;32m     59\u001b[0m                     'Test loss', testLoss.result(), step=globalStep)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInaccessibleTensorError\u001b[0m: in converted code:\n\n    <ipython-input-16-23a591338633>:89 testStep  *\n        loss = loss(patchHR, maskHR, predPatchHR)\n    ../utils/loss.py:72 shiftCompensatedL1Loss  *\n        cacheLosses = tf.stack(cacheLosses)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1165 stack\n        return gen_array_ops.pack(values, axis=axis, name=name)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py:6304 pack\n        \"Pack\", values=values, axis=axis, name=name)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py:793 _apply_op_helper\n        op_def=op_def)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py:544 create_op\n        inp = self.capture(inp)\n    /home/mark/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py:603 capture\n        % (tensor, tensor.graph, self))\n\n    InaccessibleTensorError: The tensor 'Tensor(\"mul_3:0\", shape=(10, 10), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_body_106678, id=140013908497632); accessed from: FuncGraph(name=testStep, id=140014551336048).\n    \n"
     ]
    }
   ],
   "source": [
    "fitTrainData(model, optimizer, [trainLoss, trainPSNR, testLoss, testPSNR], shiftCompensatedL1Loss,\n",
    "                 shiftCompensatedcPSNR,\n",
    "                 X_train, y, 10, 1000, 512, valData, 100,\n",
    "                 checkpoint, checkpointManager,\n",
    "                 'logs', 'models', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitTrainData(model: tf.keras.Model, optimizer: tf.keras.optimizers,\n",
    "                 metrics: List[tf.keras.metrics.Mean],\n",
    "                 lossFunc,\n",
    "                 PSNRFunc,\n",
    "                 X: np.ma.array, y: np.ma.array,\n",
    "                 batchSize: int, epochs: int, bufferSize: int,\n",
    "                 valData: List[np.ma.array], valSteps: int,\n",
    "                 checkpoint: tf.train.Checkpoint, checkpointManager: tf.train.CheckpointManager,\n",
    "                 logDir: str, ckptDir: str, saveBestOnly: bool):\n",
    "\n",
    "    trainSet = loadTrainDataAsTFDataSet(X, y[0], y[1], epochs, batchSize, bufferSize)\n",
    "    valSet = loadValDataAsTFDataSet(valData[0], valData[1], valData[2], valSteps, batchSize, bufferSize)\n",
    "\n",
    "    # Logger\n",
    "    w = tf.summary.create_file_writer(logDir)\n",
    "\n",
    "    dataSetLength = len(X)\n",
    "    totalSteps = tf.cast(dataSetLength/batchSize, tf.int64)\n",
    "    globalStep = tf.cast(checkpoint.step, tf.int64)\n",
    "    step = globalStep % totalSteps\n",
    "    epoch = 0\n",
    "\n",
    "    # Metrics\n",
    "    trainLoss, trainPSNR, testLoss, testPSNR = metrics\n",
    "\n",
    "    with w.as_default():\n",
    "        for x_batch_train, y_batch_train, y_mask_batch_train in trainSet:\n",
    "            if (totalSteps - step) == 0:\n",
    "                epoch += 1\n",
    "                step = globalStep % totalSteps\n",
    "                logger.info('Start of epoch %d' % (epoch))\n",
    "                # Reset metrics\n",
    "                trainLoss.reset_states()\n",
    "                trainPSNR.reset_states()\n",
    "                testLoss.reset_states()\n",
    "                testPSNR.reset_states()\n",
    "\n",
    "            step += 1\n",
    "            globalStep += 1\n",
    "            trainStep(x_batch_train, y_batch_train, y_mask_batch_train, checkpoint,\n",
    "                      lossFunc, PSNRFunc, trainLoss, trainPSNR)\n",
    "            checkpoint.step.assign_add(1)\n",
    "\n",
    "            t = f\"step {step}/{int(totalSteps)}, loss: {trainLoss.result():.3f}, psnr: {trainPSNR.result():.3f}\"\n",
    "            logger.info(t)\n",
    "\n",
    "            tf.summary.scalar('Train PSNR', trainPSNR.result(), step=globalStep)\n",
    "\n",
    "            tf.summary.scalar('Train loss', trainLoss.result(), step=globalStep)\n",
    "\n",
    "            if step != 0 and (step % 100) == 0:\n",
    "                # Reset states for test\n",
    "                testLoss.reset_states()\n",
    "                testPSNR.reset_states()\n",
    "                for x_batch_val, y_batch_val, y_mask_batch_val in valSet:\n",
    "                    testStep(x_batch_val, y_batch_val, y_mask_batch_val, checkpoint,\n",
    "                             lossFunc, PSNRFunc, testLoss, testPSNR)\n",
    "                tf.summary.scalar(\n",
    "                    'Test loss', testLoss.result(), step=globalStep)\n",
    "                tf.summary.scalar(\n",
    "                    'Test PSNR', testPSNR.result(), step=globalStep)\n",
    "                t = f\"Validation results... val_loss: {testLoss.result():.3f}, val_psnr: {testPSNR.result():.3f}\"\n",
    "                logger.info(t)\n",
    "                w.flush()\n",
    "\n",
    "                if saveBestOnly and (testPSNR.result() <= checkpoint.psnr):\n",
    "                    continue\n",
    "\n",
    "                checkpoint.psnr = testPSNR.result()\n",
    "                checkpointManager.save()\n",
    "\n",
    "@tf.function\n",
    "def trainStep(patchLR, patchHR, maskHR, checkpoint, loss, metric, trainLoss, trainPSNR):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        predPatchHR = checkpoint.model(patchLR, training=True)\n",
    "        loss = shiftCompensatedL1Lossv2(patchHR, maskHR, predPatchHR)  # Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor)\n",
    "\n",
    "    gradients = tape.gradient(loss, checkpoint.model.trainable_variables)\n",
    "    checkpoint.optimizer.apply_gradients(zip(gradients, checkpoint.model.trainable_variables))\n",
    "\n",
    "    metric = shiftCompensatedL1Lossv2(patchHR, maskHR, predPatchHR)\n",
    "    trainLoss(loss)\n",
    "    trainPSNR(metric)\n",
    "\n",
    "@tf.function\n",
    "def testStep(patchLR, patchHR, maskHR, checkpoint, loss, metric, testLoss, testPSNR):\n",
    "    predPatchHR = checkpoint.model(patchLR, training=False)\n",
    "    loss = loss(patchHR, maskHR, predPatchHR)\n",
    "    metric = metric(patchHR, maskHR, predPatchHR)\n",
    "\n",
    "    testLoss(loss)\n",
    "    testPSNR(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftCompensatedL1Lossv2(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The minimum L1 Loss of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    theShape = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = 96 - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = 96 - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cacheLosses = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in range(MAX_PIXEL_SHIFT+1):\n",
    "            theShape = tf.shape(cropPrediction)\n",
    "            cropTrueImg = cropImage(patchHR, i, theShape[1], j, theShape[2])\n",
    "            cropTrueMsk = cropImage(maskHR, i, theShape[1], j, theShape[2])\n",
    "            cropPredMskd = cropPrediction * cropTrueMsk\n",
    "            totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "            b = (1.0 / totalClearPixels) * tf.reduce_sum(tf.subtract(cropTrueMsk, cropPredMskd), axis=(1, 2, 3))\n",
    "            b = tf.reshape(b, (theShape[0], 1, 1, theShape[3]))\n",
    "\n",
    "    correctedCropPred = cropPrediction + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    L1Loss = computeL1Loss(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cacheLosses.append(L1Loss)\n",
    "    cacheLosses = tf.stack(cacheLosses)\n",
    "    minLoss = tf.reduce_min(cacheLosses)\n",
    "    return minLoss\n",
    "\n",
    "def shiftCompensatedL1Lossv3(yTrue, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The minimum L1 Loss of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    \n",
    "    patchHR, maskHR = yTrue\n",
    "    theShape = tf.shape(patchHR)\n",
    "    cropSizeHeight = 96 - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = 96 - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cacheLosses = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in range(MAX_PIXEL_SHIFT+1):\n",
    "            theShape = tf.shape(cropPrediction)\n",
    "            cropTrueImg = cropImage(patchHR, i, theShape[1], j, theShape[2])\n",
    "            cropTrueMsk = cropImage(maskHR, i, theShape[1], j, theShape[2])\n",
    "            cropPredMskd = cropPrediction * cropTrueMsk\n",
    "            totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "            b = (1.0 / totalClearPixels) * tf.reduce_sum(tf.subtract(cropTrueMsk, cropPredMskd), axis=(1, 2, 3))\n",
    "            b = tf.reshape(b, (theShape[0], 1, 1, theShape[3]))\n",
    "\n",
    "    correctedCropPred = cropPrediction + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    L1Loss = computeL1Loss(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cacheLosses.append(L1Loss)\n",
    "    cacheLosses = tf.stack(cacheLosses)\n",
    "    minLoss = tf.reduce_min(cacheLosses)\n",
    "    return minLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainClass import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored from checkpoint at step 300.\n"
     ]
    }
   ],
   "source": [
    "trainClass = ModelTrain(model=model,\n",
    "                       loss=shiftCompensatedL1Lossv2,\n",
    "                       metric=shiftCompensatedL1Lossv2,\n",
    "                       optimizer=Nadam(learning_rate=5e-4),\n",
    "                       ckptDir='ckpt',\n",
    "                       logDir='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WDSRConv3D(scale=3, numFilters=32, kernelSize=(3, 3, 3), numResBlocks=8,\n",
    "                expRate=8, decayRate=0.8, numImgLR=9, patchSizeLR=32, isGrayScale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(0, 1400, (100, 32, 32, 9, 1))\n",
    "y = np.random.randint(0, 1400, (100, 96, 96, 1))\n",
    "y_mask = np.random.randint(0, 2, (100, 96, 96, 1)).astype(np.bool)\n",
    "X_train, X_val, y_train, y_val, y_train_mask, y_val_mask = train_test_split(\n",
    "        X, y, y_mask, test_size=0.7, random_state=17)\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "y_train_mask = tf.convert_to_tensor(y_train_mask, dtype=tf.float32)\n",
    "y_val_mask = tf.convert_to_tensor(y_val_mask, dtype=tf.float32)\n",
    "\n",
    "y = [y_train, y_train_mask]\n",
    "valData = [X_val, y_val, y_val_mask]\n",
    "\n",
    "# Initialize metrics\n",
    "trainLoss = Mean(name='trainLoss')\n",
    "trainPSNR = Mean(name='trainPSNR')\n",
    "testLoss = Mean(name='testLoss')\n",
    "testPSNR = Mean(name='testPSNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data...\n",
      "Initialized constants...\n",
      "Starting iterations...\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:13,065 - Unresolved object in checkpoint: (root).optimizer.iter\n",
      "2020-02-28 20:05:13,066 - Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "2020-02-28 20:05:13,066 - Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "2020-02-28 20:05:13,067 - Unresolved object in checkpoint: (root).optimizer.decay\n",
      "2020-02-28 20:05:13,067 - Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "2020-02-28 20:05:13,067 - Unresolved object in checkpoint: (root).optimizer.momentum_cache\n",
      "2020-02-28 20:05:13,068 - A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "2020-02-28 20:05:13,078 - Unresolved object in checkpoint: (root).optimizer.iter\n",
      "2020-02-28 20:05:13,078 - Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "2020-02-28 20:05:13,079 - Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "2020-02-28 20:05:13,079 - Unresolved object in checkpoint: (root).optimizer.decay\n",
      "2020-02-28 20:05:13,080 - Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "2020-02-28 20:05:13,080 - Unresolved object in checkpoint: (root).optimizer.momentum_cache\n",
      "2020-02-28 20:05:13,080 - A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "2020-02-28 20:05:29,717 - step 301/1576, loss: 6374.259, psnr: 6374.259\n",
      "2020-02-28 20:05:29,832 - step 302/1576, loss: 5689.034, psnr: 5689.034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:29,948 - step 303/1576, loss: 5189.724, psnr: 5189.724\n",
      "2020-02-28 20:05:30,060 - step 304/1576, loss: 5569.954, psnr: 5569.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:30,175 - step 305/1576, loss: 4853.862, psnr: 4853.862\n",
      "2020-02-28 20:05:30,281 - step 306/1576, loss: 4784.211, psnr: 4784.211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:30,396 - step 307/1576, loss: 4942.110, psnr: 4942.110\n",
      "2020-02-28 20:05:30,504 - step 308/1576, loss: 4968.521, psnr: 4968.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:30,613 - step 309/1576, loss: 5201.692, psnr: 5201.692\n",
      "2020-02-28 20:05:30,719 - step 310/1576, loss: 5232.450, psnr: 5232.450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:30,827 - step 311/1576, loss: 5352.604, psnr: 5352.604\n",
      "2020-02-28 20:05:30,931 - step 312/1576, loss: 5465.209, psnr: 5465.209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:31,040 - step 313/1576, loss: 5399.088, psnr: 5399.088\n",
      "2020-02-28 20:05:31,146 - step 314/1576, loss: 5509.657, psnr: 5509.657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:31,254 - step 315/1576, loss: 5696.533, psnr: 5696.533\n",
      "2020-02-28 20:05:31,359 - step 316/1576, loss: 5661.505, psnr: 5661.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:31,469 - step 317/1576, loss: 5690.651, psnr: 5690.651\n",
      "2020-02-28 20:05:31,574 - step 318/1576, loss: 5680.591, psnr: 5680.591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:31,684 - step 319/1576, loss: 5725.345, psnr: 5725.345\n",
      "2020-02-28 20:05:31,790 - step 320/1576, loss: 5759.135, psnr: 5759.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:31,899 - step 321/1576, loss: 5770.252, psnr: 5770.252\n",
      "2020-02-28 20:05:32,004 - step 322/1576, loss: 5797.674, psnr: 5797.674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:32,116 - step 323/1576, loss: 5803.265, psnr: 5803.265\n",
      "2020-02-28 20:05:32,224 - step 324/1576, loss: 5852.656, psnr: 5852.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:32,328 - step 325/1576, loss: 5866.972, psnr: 5866.972\n",
      "2020-02-28 20:05:32,430 - step 326/1576, loss: 5932.915, psnr: 5932.915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:32,535 - step 327/1576, loss: 5878.287, psnr: 5878.287\n",
      "2020-02-28 20:05:32,638 - step 328/1576, loss: 5874.401, psnr: 5874.401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:32,742 - step 329/1576, loss: 5926.402, psnr: 5926.402\n",
      "2020-02-28 20:05:32,845 - step 330/1576, loss: 5976.528, psnr: 5976.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:32,948 - step 331/1576, loss: 5979.131, psnr: 5979.131\n",
      "2020-02-28 20:05:33,053 - step 332/1576, loss: 5985.898, psnr: 5985.898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:33,157 - step 333/1576, loss: 5881.754, psnr: 5881.754\n",
      "2020-02-28 20:05:33,259 - step 334/1576, loss: 5893.384, psnr: 5893.384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:33,363 - step 335/1576, loss: 5871.814, psnr: 5871.814\n",
      "2020-02-28 20:05:33,465 - step 336/1576, loss: 5857.864, psnr: 5857.864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:33,574 - step 337/1576, loss: 5867.383, psnr: 5867.383\n",
      "2020-02-28 20:05:33,678 - step 338/1576, loss: 5869.051, psnr: 5869.051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:33,781 - step 339/1576, loss: 5892.984, psnr: 5892.984\n",
      "2020-02-28 20:05:33,885 - step 340/1576, loss: 5930.562, psnr: 5930.562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:33,988 - step 341/1576, loss: 5906.574, psnr: 5906.574\n",
      "2020-02-28 20:05:34,090 - step 342/1576, loss: 5937.491, psnr: 5937.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:34,198 - step 343/1576, loss: 5944.614, psnr: 5944.614\n",
      "2020-02-28 20:05:34,305 - step 344/1576, loss: 5950.941, psnr: 5950.941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:34,411 - step 345/1576, loss: 5952.352, psnr: 5952.352\n",
      "2020-02-28 20:05:34,517 - step 346/1576, loss: 5976.208, psnr: 5976.208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:34,621 - step 347/1576, loss: 5942.380, psnr: 5942.380\n",
      "2020-02-28 20:05:34,723 - step 348/1576, loss: 5943.221, psnr: 5943.221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:34,828 - step 349/1576, loss: 5913.979, psnr: 5913.979\n",
      "2020-02-28 20:05:34,931 - step 350/1576, loss: 5917.043, psnr: 5917.043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:35,035 - step 351/1576, loss: 5929.686, psnr: 5929.686\n",
      "2020-02-28 20:05:35,139 - step 352/1576, loss: 5934.812, psnr: 5934.812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:35,248 - step 353/1576, loss: 5913.561, psnr: 5913.561\n",
      "2020-02-28 20:05:35,357 - step 354/1576, loss: 5918.582, psnr: 5918.582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:35,465 - step 355/1576, loss: 5934.980, psnr: 5934.980\n",
      "2020-02-28 20:05:35,569 - step 356/1576, loss: 5952.628, psnr: 5952.628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:35,673 - step 357/1576, loss: 5947.521, psnr: 5947.521\n",
      "2020-02-28 20:05:35,778 - step 358/1576, loss: 5919.392, psnr: 5919.392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:35,881 - step 359/1576, loss: 5939.459, psnr: 5939.459\n",
      "2020-02-28 20:05:35,983 - step 360/1576, loss: 5935.829, psnr: 5935.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:36,093 - step 361/1576, loss: 5933.177, psnr: 5933.177\n",
      "2020-02-28 20:05:36,202 - step 362/1576, loss: 5939.238, psnr: 5939.238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:36,305 - step 363/1576, loss: 5925.026, psnr: 5925.026\n",
      "2020-02-28 20:05:36,408 - step 364/1576, loss: 5904.995, psnr: 5904.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:36,512 - step 365/1576, loss: 5888.782, psnr: 5888.782\n",
      "2020-02-28 20:05:36,614 - step 366/1576, loss: 5893.807, psnr: 5893.807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:36,719 - step 367/1576, loss: 5854.120, psnr: 5854.120\n",
      "2020-02-28 20:05:36,823 - step 368/1576, loss: 5862.181, psnr: 5862.181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:36,926 - step 369/1576, loss: 5872.716, psnr: 5872.716\n",
      "2020-02-28 20:05:37,028 - step 370/1576, loss: 5876.649, psnr: 5876.649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:37,133 - step 371/1576, loss: 5891.623, psnr: 5891.623\n",
      "2020-02-28 20:05:37,239 - step 372/1576, loss: 5873.299, psnr: 5873.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:37,349 - step 373/1576, loss: 5859.513, psnr: 5859.513\n",
      "2020-02-28 20:05:37,452 - step 374/1576, loss: 5811.515, psnr: 5811.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:37,556 - step 375/1576, loss: 5826.289, psnr: 5826.289\n",
      "2020-02-28 20:05:37,661 - step 376/1576, loss: 5831.391, psnr: 5831.391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:37,764 - step 377/1576, loss: 5845.364, psnr: 5845.364\n",
      "2020-02-28 20:05:37,870 - step 378/1576, loss: 5792.840, psnr: 5792.840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:37,974 - step 379/1576, loss: 5788.969, psnr: 5788.969\n",
      "2020-02-28 20:05:38,079 - step 380/1576, loss: 5777.808, psnr: 5777.808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:38,184 - step 381/1576, loss: 5787.088, psnr: 5787.088\n",
      "2020-02-28 20:05:38,286 - step 382/1576, loss: 5812.955, psnr: 5812.955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:38,390 - step 383/1576, loss: 5826.688, psnr: 5826.688\n",
      "2020-02-28 20:05:38,493 - step 384/1576, loss: 5834.894, psnr: 5834.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:38,598 - step 385/1576, loss: 5819.586, psnr: 5819.586\n",
      "2020-02-28 20:05:38,702 - step 386/1576, loss: 5824.139, psnr: 5824.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:38,810 - step 387/1576, loss: 5838.425, psnr: 5838.425\n",
      "2020-02-28 20:05:38,919 - step 388/1576, loss: 5844.084, psnr: 5844.084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:39,025 - step 389/1576, loss: 5847.620, psnr: 5847.620\n",
      "2020-02-28 20:05:39,127 - step 390/1576, loss: 5861.954, psnr: 5861.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:39,230 - step 391/1576, loss: 5884.657, psnr: 5884.657\n",
      "2020-02-28 20:05:39,333 - step 392/1576, loss: 5894.556, psnr: 5894.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:39,440 - step 393/1576, loss: 5896.601, psnr: 5896.601\n",
      "2020-02-28 20:05:39,544 - step 394/1576, loss: 5880.836, psnr: 5880.836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:39,649 - step 395/1576, loss: 5881.892, psnr: 5881.892\n",
      "2020-02-28 20:05:39,751 - step 396/1576, loss: 5894.034, psnr: 5894.034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:39,857 - step 397/1576, loss: 5890.361, psnr: 5890.361\n",
      "2020-02-28 20:05:39,960 - step 398/1576, loss: 5876.515, psnr: 5876.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step success!!\n",
      "Iterating\n",
      "Train step success!!\n",
      "Iterating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 20:05:40,064 - step 399/1576, loss: 5878.668, psnr: 5878.668\n"
     ]
    }
   ],
   "source": [
    "trainClass.fitTrainData(X_train, y, 10, 1, 1, valData, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c74f4efbd94d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
