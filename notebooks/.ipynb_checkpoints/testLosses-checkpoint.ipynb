{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_BORDER = 3\n",
    "MAX_PIXEL_SHIFT = 2*CROP_BORDER\n",
    "\n",
    "def shiftCompensatedcPSNR(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The maximum cPSNR of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    N, H, W, C = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = H - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = W - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cachecPSNR = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "            stackcPSNR(i, j, patchHR, maskHR, cropPrediction, cachecPSNR)\n",
    "    cachecPSNR = tf.stack(cachecPSNR)\n",
    "    maxcPSNR = tf.reduce_max(cachecPSNR)\n",
    "    return maxcPSNR\n",
    "\n",
    "\n",
    "\n",
    "def shiftCompensatedL2Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The minimum L2 Loss of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    N, H, W, C = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = H - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = W - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cacheLosses = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "            stackL2Loss(i, j, patchHR, maskHR, cropPrediction, cacheLosses)\n",
    "    cacheLosses = tf.stack(cacheLosses)\n",
    "    minLoss = tf.reduce_min(cacheLosses)\n",
    "    return minLoss\n",
    "\n",
    "def shiftCompensatedL1Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The minimum L1 Loss of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    theShape = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = 96 - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = 96 - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cacheLosses = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in range(MAX_PIXEL_SHIFT+1):\n",
    "            stackL1Loss(i, j, patchHR, maskHR, cropPrediction, cacheLosses)\n",
    "    cacheLosses = tf.stack(cacheLosses)\n",
    "    minLoss = tf.reduce_min(cacheLosses)\n",
    "    return minLoss\n",
    "\n",
    "\n",
    "def shiftCompensatedL1Lossv2(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The minimum L1 Loss of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    theShape = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = 96 - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = 96 - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cacheLosses = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in range(MAX_PIXEL_SHIFT+1):\n",
    "            theShape = tf.shape(cropPrediction)\n",
    "            cropTrueImg = cropImage(patchHR, i, theShape[1], j, theShape[2])\n",
    "            cropTrueMsk = cropImage(maskHR, i, theShape[1], j, theShape[2])\n",
    "            cropPredMskd = cropPrediction * cropTrueMsk\n",
    "            totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "            b = (1.0 / totalClearPixels) * tf.reduce_sum(tf.subtract(cropTrueMsk, cropPredMskd), axis=(1, 2, 3))\n",
    "            b = tf.reshape(b, (theShape[0], 1, 1, theShape[3]))\n",
    "\n",
    "    correctedCropPred = cropPrediction + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    L1Loss = computeL1Loss(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cacheLosses.append(L1Loss)\n",
    "    cacheLosses = tf.stack(cacheLosses)\n",
    "    minLoss = tf.reduce_min(cacheLosses)\n",
    "    return minLoss\n",
    "\n",
    "\n",
    "def stackL1Loss(i: int, j: int, patchHR: tf.Tensor, maskHR: tf.Tensor, cropPred: tf.Tensor, cache: List[float]):\n",
    "    #N, cropSizeHeight, cropSizeWidth, C = tf.shape(cropPred)\n",
    "    theShape = tf.shape(cropPred)\n",
    "    cropTrueImg = cropImage(patchHR, i, theShape[1], j, theShape[2])\n",
    "    cropTrueMsk = cropImage(maskHR, i, theShape[1], j, theShape[2])\n",
    "    cropPredMskd = cropPred * cropTrueMsk\n",
    "    totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "    b = computeBiasBrightness(totalClearPixels, cropTrueImg, cropPredMskd)\n",
    "\n",
    "    correctedCropPred = cropPred + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    L1Loss = computeL1Loss(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cache.append(L1Loss)\n",
    "\n",
    "\n",
    "\n",
    "def stackL2Loss(i: int, j: int, patchHR: tf.Tensor, maskHR: tf.Tensor, cropPred: tf.Tensor, cache: List[float]):\n",
    "    N, cropSizeHeight, cropSizeWidth, C = tf.shape(cropPred)\n",
    "    cropTrueImg = cropImage(patchHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropTrueMsk = cropImage(maskHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropPredMskd = cropPred * cropTrueMsk\n",
    "    totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "    b = computeBiasBrightness(totalClearPixels, cropTrueImg, cropPredMskd)\n",
    "\n",
    "    correctedCropPred = cropPred + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    L2Loss = computeL2Loss(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cache.append(L2Loss)\n",
    "\n",
    "\n",
    "def stackcPSNR(i: int, j: int, patchHR: tf.Tensor, maskHR: tf.Tensor, cropPred: tf.Tensor, cache: List[float]):\n",
    "    N, cropSizeHeight, cropSizeWidth, C = tf.shape(cropPred)\n",
    "    cropTrueImg = cropImage(patchHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropTrueMsk = cropImage(maskHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropPredMskd = cropPred * cropTrueMsk\n",
    "    totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "    b = computeBiasBrightness(totalClearPixels, cropTrueImg, cropPredMskd)\n",
    "\n",
    "    correctedCropPred = cropPred + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    cPSNR = computecPSNR(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cache.append(cPSNR)\n",
    "\n",
    "\n",
    "def computeL1Loss(totalClearPixels, HR, correctedSR):\n",
    "    loss = (1.0 / totalClearPixels) * tf.reduce_sum(tf.abs(tf.subtract(HR, correctedSR)), axis=(1, 2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def computeL2Loss(totalClearPixels, HR, correctedSR):\n",
    "    loss = (1.0 / totalClearPixels) * tf.reduce_sum(tf.square(tf.subtract(HR, correctedSR)), axis=(1, 2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def computecPSNR(totalClearPixels, HR, correctedSR):\n",
    "    loss = (1.0 / totalClearPixels) * tf.reduce_sum(tf.square(tf.subtract(HR, correctedSR)), axis=(1, 2))\n",
    "    cPSNR = -tf.math.log(loss) / tf.math.log(tf.constant(10, dtype=tf.float32))\n",
    "    return cPSNR\n",
    "\n",
    "\n",
    "def computeBiasBrightness(totalClearPixels, HR, SR):\n",
    "    theShape = tf.shape(HR)\n",
    "    b = (1.0 / totalClearPixels) * tf.reduce_sum(tf.subtract(HR, SR), axis=(1, 2, 3))\n",
    "    b = tf.reshape(b, (theShape[0], 1, 1, theShape[3]))\n",
    "    return b\n",
    "\n",
    "\n",
    "def cropImage(imgBatch: tf.Tensor, startIdxH: int, lengthHeight: int,\n",
    "              startIdxW: int, lengthWidth: int) -> tf.Tensor:\n",
    "    return tf.cast(imgBatch[:, startIdxH: startIdxH + lengthHeight, startIdxW: startIdxW + lengthWidth, :], tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchLR = np.random.randint(0, 1400, (10, 32, 32, 9, 1))\n",
    "patchHR = np.random.randint(0, 1400, (10, 96, 96, 1))\n",
    "maskHR = np.random.randint(0, 2, (10, 96, 96, 1)).astype(np.bool)\n",
    "predPatchHR = np.random.randint(0, 1400, (10, 96, 96, 1))\n",
    "patchLR = tf.convert_to_tensor(patchLR, dtype=tf.float32)\n",
    "patchHR = tf.convert_to_tensor(patchHR, dtype=tf.float32)\n",
    "maskHR = tf.convert_to_tensor(maskHR, dtype=tf.bool)\n",
    "predPatchHR = tf.convert_to_tensor(predPatchHR, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam(learning_rate=5e-4)\n",
    "\n",
    "@tf.function\n",
    "def trainStep(patchLR, patchHR, maskHR, model):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        predPatchHR = model(patchLR, training=True)\n",
    "        loss = shiftCompensatedL1Lossv2(patchHR, maskHR, predPatchHR)  # Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1387349.63\r\n"
     ]
    }
   ],
   "source": [
    "tf.print(shiftCompensatedL2Loss(patchHR, maskHR, predPatchHR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.14218616\r\n"
     ]
    }
   ],
   "source": [
    "tf.print(shiftCompensatedcPSNR(patchHR, maskHR, predPatchHR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396.08716\r\n"
     ]
    }
   ],
   "source": [
    "tf.print(shiftCompensatedL1Loss(patchHR, maskHR, predPatchHR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WDSRConv3D(scale=3, numFilters=32, kernelSize=(3, 3, 3), numResBlocks=8,\n",
    "                expRate=8, decayRate=0.8, numImgLR=9, patchSizeLR=32, isGrayScale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-5-4cbf4aa26191>:11 trainStep  *\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py:434 apply_gradients\n        self._create_slots(var_list)\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\nadam.py:119 _create_slots\n        self.add_slot(var, 'm')\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py:599 add_slot\n        initial_value=initial_value)\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:260 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:254 _variable_v2_call\n        shape=shape)\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:65 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py:502 invalid_creator_scope\n        \"tf.function-decorated function tried to create \"\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b64ae35fc997>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatchLR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatchHR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaskHR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2360\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2362\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2363\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-5-4cbf4aa26191>:11 trainStep  *\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py:434 apply_gradients\n        self._create_slots(var_list)\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\nadam.py:119 _create_slots\n        self.add_slot(var, 'm')\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py:599 add_slot\n        initial_value=initial_value)\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:260 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:254 _variable_v2_call\n        shape=shape)\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:65 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\users\\marka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py:502 invalid_creator_scope\n        \"tf.function-decorated function tried to create \"\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n"
     ]
    }
   ],
   "source": [
    "trainStep(patchLR, patchHR, maskHR, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"WDSRConv3D\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 32, 32, 9, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "initPad (Lambda)                (None, 34, 34, 9, 1) 0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normImgLR (Lambda)              (None, 34, 34, 9, 1) 0           initPad[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mainConv1 (WeightNormalization) (None, 34, 34, 9, 32 929         normImgLR[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expConv_0 (WeightNormalization) (None, 34, 34, 9, 25 8705        mainConv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decConv_0 (WeightNormalization) (None, 34, 34, 9, 25 6451        expConv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "normConv_0 (WeightNormalization (None, 34, 34, 9, 32 21665       decConv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AddResConv_0 (Add)              (None, 34, 34, 9, 32 0           normConv_0[0][0]                 \n",
      "                                                                 mainConv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expConv_1 (WeightNormalization) (None, 34, 34, 9, 25 8705        AddResConv_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decConv_1 (WeightNormalization) (None, 34, 34, 9, 25 6451        expConv_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "normConv_1 (WeightNormalization (None, 34, 34, 9, 32 21665       decConv_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AddResConv_1 (Add)              (None, 34, 34, 9, 32 0           normConv_1[0][0]                 \n",
      "                                                                 AddResConv_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "expConv_2 (WeightNormalization) (None, 34, 34, 9, 25 8705        AddResConv_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decConv_2 (WeightNormalization) (None, 34, 34, 9, 25 6451        expConv_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "normConv_2 (WeightNormalization (None, 34, 34, 9, 32 21665       decConv_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AddResConv_2 (Add)              (None, 34, 34, 9, 32 0           normConv_2[0][0]                 \n",
      "                                                                 AddResConv_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "expConv_3 (WeightNormalization) (None, 34, 34, 9, 25 8705        AddResConv_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decConv_3 (WeightNormalization) (None, 34, 34, 9, 25 6451        expConv_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "normConv_3 (WeightNormalization (None, 34, 34, 9, 32 21665       decConv_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AddResConv_3 (Add)              (None, 34, 34, 9, 32 0           normConv_3[0][0]                 \n",
      "                                                                 AddResConv_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "expConv_4 (WeightNormalization) (None, 34, 34, 9, 25 8705        AddResConv_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decConv_4 (WeightNormalization) (None, 34, 34, 9, 25 6451        expConv_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "normConv_4 (WeightNormalization (None, 34, 34, 9, 32 21665       decConv_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AddResConv_4 (Add)              (None, 34, 34, 9, 32 0           normConv_4[0][0]                 \n",
      "                                                                 AddResConv_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "expConv_5 (WeightNormalization) (None, 34, 34, 9, 25 8705        AddResConv_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decConv_5 (WeightNormalization) (None, 34, 34, 9, 25 6451        expConv_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "normConv_5 (WeightNormalization (None, 34, 34, 9, 32 21665       decConv_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AddResConv_5 (Add)              (None, 34, 34, 9, 32 0           normConv_5[0][0]                 \n",
      "                                                                 AddResConv_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "expConv_6 (WeightNormalization) (None, 34, 34, 9, 25 8705        AddResConv_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decConv_6 (WeightNormalization) (None, 34, 34, 9, 25 6451        expConv_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "normConv_6 (WeightNormalization (None, 34, 34, 9, 32 21665       decConv_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AddResConv_6 (Add)              (None, 34, 34, 9, 32 0           normConv_6[0][0]                 \n",
      "                                                                 AddResConv_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "expConv_7 (WeightNormalization) (None, 34, 34, 9, 25 8705        AddResConv_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decConv_7 (WeightNormalization) (None, 34, 34, 9, 25 6451        expConv_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "normConv_7 (WeightNormalization (None, 34, 34, 9, 32 21665       decConv_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AddResConv_7 (Add)              (None, 34, 34, 9, 32 0           normConv_7[0][0]                 \n",
      "                                                                 AddResConv_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "convReducePad_0 (Lambda)        (None, 36, 36, 9, 32 0           AddResConv_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_124 (Weigh (None, 34, 34, 7, 32 27713       convReducePad_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "convReducePad_1 (Lambda)        (None, 36, 36, 7, 32 0           weight_normalization_124[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_125 (Weigh (None, 34, 34, 5, 32 27713       convReducePad_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "getMeanLR (Lambda)              (None, 34, 34, 1)    0           initPad[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convReducePad_2 (Lambda)        (None, 36, 36, 5, 32 0           weight_normalization_125[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "normMeanImgLR (Lambda)          (None, 34, 34, 1)    0           getMeanLR[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_126 (Weigh (None, 34, 34, 3, 32 27713       convReducePad_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "padResid (Lambda)               (None, 36, 36, 1)    0           normMeanImgLR[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "upscaleConv (WeightNormalizatio (None, 32, 32, 1, 9) 7795        weight_normalization_126[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "residConv1 (WeightNormalization (None, 34, 34, 9)    100         padResid[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshapeMain (Reshape)           (None, 32, 32, 9)    0           upscaleConv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "residConv2 (WeightNormalization (None, 32, 32, 9)    748         residConv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dtsMain (Lambda)                (None, 96, 96, 1)    0           reshapeMain[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dtsResid (Lambda)               (None, 96, 96, 1)    0           residConv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mainPlusResid (Add)             (None, 96, 96, 1)    0           dtsMain[0][0]                    \n",
      "                                                                 dtsResid[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "denorm (Lambda)                 (None, 96, 96, 1)    0           mainPlusResid[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 387,279\n",
      "Trainable params: 387,248\n",
      "Non-trainable params: 31\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv3D, Conv2D, Lambda, Add, Reshape\n",
    "\n",
    "\n",
    "def WDSRConv3D(scale: int, numFilters: int, kernelSize: tuple,\n",
    "               numResBlocks: int, expRate: int, decayRate: float,\n",
    "               numImgLR: int, patchSizeLR: int, isGrayScale: bool) -> Model:\n",
    "    # Define inputs\n",
    "    imgLRIn = Input(shape=(patchSizeLR, patchSizeLR, numImgLR, 1)) if isGrayScale \\\n",
    "        else Input(shape=(patchSizeLR, patchSizeLR, numImgLR, 3))\n",
    "\n",
    "    # Get mean of instance mean patch and over all mean pixel value\n",
    "    imgLR = Lambda(lambda x: tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0], [0, 0]], mode='reflect'), name='initPad')(imgLRIn)\n",
    "    meanImgLR = Lambda(lambda x: tf.reduce_mean(x, axis=3, name='meanLR'), name='getMeanLR')(imgLR)\n",
    "    allMean = Lambda(lambda x: tf.reduce_mean(x, name='allMean'), name='getAllMean')(imgLR)\n",
    "    allStdDev = Lambda(lambda x: tf.math.reduce_std(x, name='allStdDev'), name='getAllStdDev')(imgLR)\n",
    "\n",
    "    # Normalize Instance\n",
    "    imgLR = Lambda(lambda x: tf.math.divide(tf.math.subtract(x, allMean, name='normSub1'), allStdDev, name='normDiv1'), name='normImgLR')(imgLR)\n",
    "    meanImgLR = Lambda(lambda x: tf.math.divide(tf.math.subtract(x, allMean, name='normSub2'), allStdDev, name='normDiv2'), name='normMeanImgLR')(meanImgLR)\n",
    "\n",
    "    # ImgResBlocks | Main Path\n",
    "    main = WDSRNetMainPath(imgLR, numFilters, kernelSize,\n",
    "                           numResBlocks, patchSizeLR, numImgLR,\n",
    "                           scale, expRate, decayRate)\n",
    "\n",
    "    # MeanResBlocks | Residual Path\n",
    "    residual = WDSRNetResidualPath(meanImgLR, kernelSize[:-1], scale)\n",
    "\n",
    "    # Fuse Main and Residual Patch\n",
    "    out = Add(name='mainPlusResid')([main, residual])\n",
    "\n",
    "    # Denormalize Instance\n",
    "    out = Lambda(lambda x: tf.math.add(tf.math.multiply(x, allStdDev, name='denormMul'), allMean, name='denormAdd'), name='denorm')(out)\n",
    "\n",
    "    return Model(imgLRIn, out, name='WDSRConv3D')\n",
    "\n",
    "\n",
    "def WDSRNetResidualPath(meanImgLR: tf.Tensor, kernelSize: tuple, scale: int):\n",
    "    x = Lambda(lambda x: tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT'), name='padResid')(meanImgLR)\n",
    "    x = weightNormedConv2D(outChannels=scale*scale, kernelSize=kernelSize, padding='valid', activation='relu', name='residConv1')(x)\n",
    "    x = weightNormedConv2D(outChannels=scale*scale, kernelSize=kernelSize, padding='valid', name='residConv2')(x)\n",
    "    x = Lambda(lambda x: tf.nn.depth_to_space(x, scale), name='dtsResid')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def WDSRNetMainPath(imgLR: tf.Tensor, numFilters: int, kernelSize: tuple,\n",
    "                    numResBlocks: int, patchSizeLR: int, numImgLR: int,\n",
    "                    scale: int, expRate: int, decayRate: int):\n",
    "    x = weightNormedConv3D(numFilters, kernelSize, 'same', activation='relu', name='mainConv1')(imgLR)\n",
    "    for i in range(numResBlocks):\n",
    "        x = ResConv3D(x, numFilters, expRate, decayRate, kernelSize, i)\n",
    "\n",
    "    x = ConvReduceAndUpscale(x, numImgLR, scale, numFilters, kernelSize)\n",
    "    x = Reshape((patchSizeLR, patchSizeLR, scale*scale), name='reshapeMain')(x)\n",
    "    x = Lambda(lambda x: tf.nn.depth_to_space(x, scale), name='dtsMain')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ConvReduceAndUpscale(x: tf.Tensor, numImgLR: int, scale: int, numFilters: int, kernelSize: tuple):\n",
    "    # Conv Reducer\n",
    "    for i in range(numImgLR//scale):\n",
    "        x = Lambda(lambda x: tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0], [0, 0]], mode='reflect'), name=f'convReducePad_{i}')(x)\n",
    "        x = weightNormedConv3D(numFilters, kernelSize, padding='valid', activation='relu', name=f'convReducer_{i}')(x)\n",
    "    # Upscale block\n",
    "    x = weightNormedConv3D(outChannels=scale*scale, kernelSize=kernelSize, padding='valid', name='upscaleConv')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResConv3D(xIn: tf.Tensor, numFilters: int, expRate: int, decayRate: float, kernelSize: int, blockNum: int):\n",
    "    # Expansion Conv3d | Same padding\n",
    "    x = weightNormedConv3D(outChannels=numFilters*expRate, kernelSize=1, padding='same', activation='relu', name=f'expConv_{blockNum}')(xIn)\n",
    "    # Decay Conv3d | Same padding\n",
    "    x = weightNormedConv3D(outChannels=int(numFilters*decayRate), kernelSize=1, padding='same', name=f'decConv_{blockNum}')(x)\n",
    "    # Norm Conv3D | Same padding\n",
    "    x = weightNormedConv3D(outChannels=numFilters, kernelSize=kernelSize, padding='same', name=f'normConv_{blockNum}')(x)\n",
    "    # Add input and result\n",
    "    out = Add(name=f'AddResConv_{blockNum}')([x, xIn])\n",
    "    return out\n",
    "\n",
    "\n",
    "def weightNormedConv3D(outChannels: int, kernelSize: int, padding: str, activation=None, name=''):\n",
    "    return WeightNormalization(Conv3D(outChannels, kernelSize, padding=padding, activation=activation),\n",
    "                               data_init=False, name=name)\n",
    "\n",
    "\n",
    "def weightNormedConv2D(outChannels: int, kernelSize: int, padding: str, activation=None, name=''):\n",
    "    return WeightNormalization(Conv2D(outChannels, kernelSize, padding=padding, activation=activation),\n",
    "                               data_init=False, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
