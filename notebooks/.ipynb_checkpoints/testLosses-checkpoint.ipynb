{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_BORDER = 3\n",
    "MAX_PIXEL_SHIFT = 2*CROP_BORDER\n",
    "\n",
    "def shiftCompensatedcPSNR(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The maximum cPSNR of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    N, H, W, C = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = H - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = W - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cachecPSNR = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "            stackcPSNR(i, j, patchHR, maskHR, cropPrediction, cachecPSNR)\n",
    "    cachecPSNR = tf.stack(cachecPSNR)\n",
    "    maxcPSNR = tf.reduce_max(cachecPSNR)\n",
    "    return maxcPSNR\n",
    "\n",
    "\n",
    "\n",
    "def shiftCompensatedL2Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The minimum L2 Loss of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    N, H, W, C = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = H - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = W - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cacheLosses = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "            stackL2Loss(i, j, patchHR, maskHR, cropPrediction, cacheLosses)\n",
    "    cacheLosses = tf.stack(cacheLosses)\n",
    "    minLoss = tf.reduce_min(cacheLosses)\n",
    "    return minLoss\n",
    "\n",
    "\n",
    "def shiftCompensatedL1Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The minimum L1 Loss of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    N, H, W, C = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = H - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = W - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cacheLosses = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "            stackL1Loss(i, j, patchHR, maskHR, cropPrediction, cacheLosses)\n",
    "    cacheLosses = tf.stack(cacheLosses)\n",
    "    minLoss = tf.reduce_min(cacheLosses)\n",
    "    return minLoss\n",
    "\n",
    "\n",
    "def stackL1Loss(i: int, j: int, patchHR: tf.Tensor, maskHR: tf.Tensor, cropPred: tf.Tensor, cache: List[float]):\n",
    "    N, cropSizeHeight, cropSizeWidth, C = tf.shape(cropPred)\n",
    "    cropTrueImg = cropImage(patchHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropTrueMsk = cropImage(maskHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropPredMskd = cropPred * cropTrueMsk\n",
    "    totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "    b = computeBiasBrightness(totalClearPixels, cropTrueImg, cropPredMskd)\n",
    "\n",
    "    correctedCropPred = cropPred + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    L1Loss = computeL1Loss(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cache.append(L1Loss)\n",
    "\n",
    "\n",
    "\n",
    "def stackL2Loss(i: int, j: int, patchHR: tf.Tensor, maskHR: tf.Tensor, cropPred: tf.Tensor, cache: List[float]):\n",
    "    N, cropSizeHeight, cropSizeWidth, C = tf.shape(cropPred)\n",
    "    cropTrueImg = cropImage(patchHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropTrueMsk = cropImage(maskHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropPredMskd = cropPred * cropTrueMsk\n",
    "    totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "    b = computeBiasBrightness(totalClearPixels, cropTrueImg, cropPredMskd)\n",
    "\n",
    "    correctedCropPred = cropPred + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    L2Loss = computeL2Loss(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cache.append(L2Loss)\n",
    "\n",
    "\n",
    "def stackcPSNR(i: int, j: int, patchHR: tf.Tensor, maskHR: tf.Tensor, cropPred: tf.Tensor, cache: List[float]):\n",
    "    N, cropSizeHeight, cropSizeWidth, C = tf.shape(cropPred)\n",
    "    cropTrueImg = cropImage(patchHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropTrueMsk = cropImage(maskHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropPredMskd = cropPred * cropTrueMsk\n",
    "    totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "    b = computeBiasBrightness(totalClearPixels, cropTrueImg, cropPredMskd)\n",
    "\n",
    "    correctedCropPred = cropPred + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    cPSNR = computecPSNR(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cache.append(cPSNR)\n",
    "\n",
    "\n",
    "def computeL1Loss(totalClearPixels, HR, correctedSR):\n",
    "    loss = (1.0 / totalClearPixels) * tf.reduce_sum(tf.abs(tf.subtract(HR, correctedSR)), axis=(1, 2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def computeL2Loss(totalClearPixels, HR, correctedSR):\n",
    "    loss = (1.0 / totalClearPixels) * tf.reduce_sum(tf.square(tf.subtract(HR, correctedSR)), axis=(1, 2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def computecPSNR(totalClearPixels, HR, correctedSR):\n",
    "    loss = (1.0 / totalClearPixels) * tf.reduce_sum(tf.square(tf.subtract(HR, correctedSR)), axis=(1, 2))\n",
    "    cPSNR = -tf.math.log(loss) / tf.math.log(tf.constant(10, dtype=tf.float32))\n",
    "    return cPSNR\n",
    "\n",
    "\n",
    "def computeBiasBrightness(totalClearPixels, HR, SR):\n",
    "    N, H, W, C = tf.shape(HR)\n",
    "    b = (1.0 / totalClearPixels) * tf.reduce_sum(tf.subtract(HR, SR), axis=(1, 2, 3))\n",
    "    b = tf.reshape(b, (N, 1, 1, C))\n",
    "    return b\n",
    "\n",
    "\n",
    "def cropImage(imgBatch: tf.Tensor, startIdxH: int, lengthHeight: int,\n",
    "              startIdxW: int, lengthWidth: int) -> tf.Tensor:\n",
    "    return tf.cast(imgBatch[:, startIdxH: startIdxH + lengthHeight, startIdxW: startIdxW + lengthWidth, :], tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchHR = np.random.randint(0, 1400, (10, 96, 96, 1))\n",
    "maskHR = np.random.randint(0, 2, (10, 96, 96, 1)).astype(np.bool)\n",
    "predPatchHR = np.random.randint(0, 1400, (10, 96, 96, 1))\n",
    "patchHR = tf.convert_to_tensor(patchHR, dtype=tf.float32)\n",
    "maskHR = tf.convert_to_tensor(maskHR, dtype=tf.bool)\n",
    "predPatchHR = tf.convert_to_tensor(predPatchHR, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 96 1\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n",
      "[10]\n",
      "[10 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "N, H, W, C = tf.shape(patchHR)\n",
    "tf.print(H, W, C)\n",
    "cropSizeHeight = H - MAX_PIXEL_SHIFT\n",
    "cropSizeWidth = W - MAX_PIXEL_SHIFT\n",
    "cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "cacheLosses = []\n",
    "\n",
    "for i in range(MAX_PIXEL_SHIFT+1):\n",
    "    for j in range(MAX_PIXEL_SHIFT+1):\n",
    "\n",
    "        N, cropSizeHeight, cropSizeWidth, C = tf.shape(cropPrediction)\n",
    "        cropTrueImg = cropImage(patchHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "        cropTrueMsk = cropImage(maskHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "        cropPredMskd = cropPrediction * cropTrueMsk\n",
    "        totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "        N, H, W, C = tf.shape(cropTrueImg)\n",
    "        b = (1.0 / totalClearPixels) * tf.reduce_sum(tf.subtract(cropTrueImg, cropPredMskd), axis=(1, 2, 3))\n",
    "        tf.print(tf.shape(b))\n",
    "        b = tf.reshape(b, (N, 1, 1, C))\n",
    "        tf.print(tf.shape(b))\n",
    "\n",
    "\n",
    "\n",
    "        correctedCropPred = cropPrediction + b\n",
    "        correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "        L1Loss = computeL1Loss(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "        cacheLosses.append(L1Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackL1Loss(i, j, patchHR, maskHR, cropPrediction, cacheLosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, C = tf.shape(patchHR)\n",
    "\n",
    "cropSizeHeight = H - MAX_PIXEL_SHIFT\n",
    "cropSizeWidth = W - MAX_PIXEL_SHIFT\n",
    "cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "cacheLosses = []\n",
    "\n",
    "for i in range(MAX_PIXEL_SHIFT+1):\n",
    "    for j in range(MAX_PIXEL_SHIFT+1):\n",
    "        stackL1Loss(i, j, patchHR, maskHR, cropPrediction, cacheLosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1418917.38\n"
     ]
    }
   ],
   "source": [
    "tf.print(shiftCompensatedL2Loss(patchHR, maskHR, predPatchHR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.15195656\n"
     ]
    }
   ],
   "source": [
    "tf.print(shiftCompensatedcPSNR(patchHR, maskHR, predPatchHR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1421.98535\n"
     ]
    }
   ],
   "source": [
    "tf.print(shiftCompensatedL1Loss(patchHR, maskHR, predPatchHR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
