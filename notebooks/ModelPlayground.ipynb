{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "sys.path.insert(0, '..')\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger('__name__')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Nadam\n",
    "\n",
    "from modelsTF import *\n",
    "from loss import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (52563, 32, 32, 9, 1) --------> Output shape: (52563, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "CLEAN_DATA_DIR = '/home/mark/DataBank/PROBA-V-CHKPT/trimmedPatchesDir'\n",
    "band = 'NIR'\n",
    "X_train = np.load(os.path.join(CLEAN_DATA_DIR, f'TRAINpatchesLR_{band}.npy'), allow_pickle=True)\n",
    "y_train = np.load(os.path.join(CLEAN_DATA_DIR, f'TRAINpatchesHR_{band}.npy'), allow_pickle=True)\n",
    "\n",
    "X = X_train.transpose((0, 3, 4, 2, 1))\n",
    "y = y_train.transpose((0, 3, 4, 2, 1)).squeeze(3)\n",
    "print(f'Input shape: {X.shape} --------> Output shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WDSRConv3D(scale=3, numFilters=32, kernelSize=(3, 3, 3), numResBlocks=8,\n",
    "                expRate=8, decayRate=0.8, numImgLR=9, patchSizeLR=32, isGrayScale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam(learning_rate=5e-4)\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                     psnr=tf.Variable(1.0),\n",
    "                                     optimizer=optimizer,\n",
    "                                     model=model)\n",
    "checkpointManager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
    "                                                   directory='/home/mark/DataBank/PROBA-V-CHKPT/models',\n",
    "                                                   max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainDataAsTFDataSet(X, y, y_mask, epochs, batchSize, bufferSize):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (X, y, y_mask)).shuffle(bufferSize, reshuffle_each_iteration=True).repeat(epochs).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "def loadValDataAsTFDataSet(X, y, y_mask, valSteps, batchSize, bufferSize):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (X, y, y_mask)).shuffle(bufferSize).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE).take(valSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, y_train_mask, y_val_mask = train_test_split(\n",
    "        X, y, y.mask, test_size=0.7, random_state=17)\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "y_train_mask = tf.convert_to_tensor(y_train_mask, dtype=tf.bool)\n",
    "y_val_mask = tf.convert_to_tensor(y_val_mask, dtype=tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [y_train, y_train_mask]\n",
    "valData = [X_val, y_val, y_val_mask]\n",
    "\n",
    "# Initialize metrics\n",
    "trainLoss = Mean(name='trainLoss')\n",
    "trainPSNR = Mean(name='trainPSNR')\n",
    "testLoss = Mean(name='testLoss')\n",
    "testPSNR = Mean(name='testPSNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in converted code:\n\n    <ipython-input-18-bc8032105ca2>:77 trainStep  *\n        loss = loss(patchHR, maskHR, predPatchHR)  # Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor)\n    <ipython-input-20-2946dba5cce9>:52 shiftCompensatedL1Loss  *\n        N, H, W, C = tf.shape(patchHR)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:539 __iter__\n        self._disallow_iteration()\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:532 _disallow_iteration\n        self._disallow_when_autograph_enabled(\"iterating over `tf.Tensor`\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:510 _disallow_when_autograph_enabled\n        \" decorating it directly with @tf.function.\".format(task))\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5a0a300d1fcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointManager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                  '/home/mark/DataBank/PROBA-V-CHKPT/logs', '/home/mark/DataBank/PROBA-V-CHKPT/models', 1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-bc8032105ca2>\u001b[0m in \u001b[0;36mfitTrainData\u001b[0;34m(model, optimizer, metrics, lossFunc, PSNRFunc, X, y, batchSize, epochs, bufferSize, valData, valSteps, checkpoint, checkpointManager, logDir, ckptDir, saveBestOnly)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mglobalStep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             trainStep(x_batch_train, y_batch_train, y_mask_batch_train, checkpoint,\n\u001b[0;32m---> 41\u001b[0;31m                       lossFunc, PSNRFunc, trainLoss, trainPSNR)\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in converted code:\n\n    <ipython-input-18-bc8032105ca2>:77 trainStep  *\n        loss = loss(patchHR, maskHR, predPatchHR)  # Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor)\n    <ipython-input-20-2946dba5cce9>:52 shiftCompensatedL1Loss  *\n        N, H, W, C = tf.shape(patchHR)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:539 __iter__\n        self._disallow_iteration()\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:532 _disallow_iteration\n        self._disallow_when_autograph_enabled(\"iterating over `tf.Tensor`\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:510 _disallow_when_autograph_enabled\n        \" decorating it directly with @tf.function.\".format(task))\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\n"
     ]
    }
   ],
   "source": [
    "fitTrainData(model, optimizer, [trainLoss, trainPSNR, testLoss, testPSNR], shiftCompensatedL1Loss,\n",
    "                 shiftCompensatedcPSNR,\n",
    "                 X_train, y, 1024, 1000, 512, valData, 100,\n",
    "                 checkpoint, checkpointManager,\n",
    "                 '/home/mark/DataBank/PROBA-V-CHKPT/logs', '/home/mark/DataBank/PROBA-V-CHKPT/models', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitTrainData(model: tf.keras.Model, optimizer: tf.keras.optimizers,\n",
    "                 metrics: List[tf.keras.metrics.Mean],\n",
    "                 lossFunc,\n",
    "                 PSNRFunc,\n",
    "                 X: np.ma.array, y: np.ma.array,\n",
    "                 batchSize: int, epochs: int, bufferSize: int,\n",
    "                 valData: List[np.ma.array], valSteps: int,\n",
    "                 checkpoint: tf.train.Checkpoint, checkpointManager: tf.train.CheckpointManager,\n",
    "                 logDir: str, ckptDir: str, saveBestOnly: bool):\n",
    "\n",
    "    trainSet = loadTrainDataAsTFDataSet(X, y[0], y[1], epochs, batchSize, bufferSize)\n",
    "    valSet = loadValDataAsTFDataSet(valData[0], valData[1], valData[2], valSteps, batchSize, bufferSize)\n",
    "\n",
    "    # Logger\n",
    "    w = tf.summary.create_file_writer(logDir)\n",
    "\n",
    "    dataSetLength = len(X)\n",
    "    totalSteps = tf.cast(dataSetLength/batchSize, tf.int64)\n",
    "    globalStep = tf.cast(checkpoint.step, tf.int64)\n",
    "    step = globalStep % totalSteps\n",
    "    epoch = 0\n",
    "\n",
    "    # Metrics\n",
    "    trainLoss, trainPSNR, testLoss, testPSNR = metrics\n",
    "\n",
    "    with w.as_default():\n",
    "        for x_batch_train, y_batch_train, y_mask_batch_train in trainSet:\n",
    "            if (totalSteps - step) == 0:\n",
    "                epoch += 1\n",
    "                step = globalStep % totalSteps\n",
    "                logger.info('Start of epoch %d' % (epoch))\n",
    "                # Reset metrics\n",
    "                trainLoss.reset_states()\n",
    "                trainPSNR.reset_states()\n",
    "                testLoss.reset_states()\n",
    "                testPSNR.reset_states()\n",
    "\n",
    "            step += 1\n",
    "            globalStep += 1\n",
    "            trainStep(x_batch_train, y_batch_train, y_mask_batch_train, checkpoint,\n",
    "                      lossFunc, PSNRFunc, trainLoss, trainPSNR)\n",
    "            checkpoint.step.assign_add(1)\n",
    "\n",
    "            t = f\"step {step}/{int(totalSteps)}, loss: {trainLoss.result():.3f}, psnr: {trainPSNR.result():.3f}\"\n",
    "            logger.info(t)\n",
    "\n",
    "            tf.summary.scalar('Train PSNR', trainPSNR.result(), step=globalStep)\n",
    "\n",
    "            tf.summary.scalar('Train loss', trainLoss.result(), step=globalStep)\n",
    "\n",
    "            if step != 0 and (step % opt.evalTestStep) == 0:\n",
    "                # Reset states for test\n",
    "                testLoss.reset_states()\n",
    "                testPSNR.reset_states()\n",
    "                for x_batch_val, y_batch_val, y_mask_batch_val in valSet:\n",
    "                    testStep(x_batch_val, y_batch_val, y_mask_batch_val, checkpoint,\n",
    "                             lossFunc, PSNRFunc, testLoss, testPSNR)\n",
    "                tf.summary.scalar(\n",
    "                    'Test loss', testLoss.result(), step=globalStep)\n",
    "                tf.summary.scalar(\n",
    "                    'Test PSNR', testPSNR.result(), step=globalStep)\n",
    "                t = f\"Validation results... val_loss: {testLoss.result():.3f}, val_psnr: {testPSNR.result():.3f}\"\n",
    "                logger.info(t)\n",
    "                w.flush()\n",
    "\n",
    "                if saveBestOnly and (testPSNR.result() <= checkpoint.psnr):\n",
    "                    continue\n",
    "\n",
    "                checkpoint.psnr = testPSNR.result()\n",
    "                checkpointManager.save()\n",
    "\n",
    "\n",
    "def trainStep(patchLR, patchHR, maskHR, checkpoint, loss, metric, trainLoss, trainPSNR):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        predPatchHR = checkpoint.model(patchLR, training=True)\n",
    "        loss = shiftCompensatedL1Loss(patchHR, maskHR, predPatchHR)  # Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor)\n",
    "\n",
    "    gradients = tape.gradient(loss, checkpoint.model.trainable_variables)\n",
    "    checkpoint.optimizer.apply_gradients(zip(gradients, checkpoint.model.trainable_variables))\n",
    "\n",
    "    metric = metric(patchHR, maskHR, predPatchHR)\n",
    "    trainLoss(loss)\n",
    "    trainPSNR(metric)\n",
    "\n",
    "\n",
    "def testStep(patchLR, patchHR, maskHR, checkpoint, loss, metric, testLoss, testPSNR):\n",
    "    sr = checkpoint.model(patchLR, training=False)\n",
    "    loss = loss(patchHR, maskHR, predPatchHR)\n",
    "    metric = metric(patchHR, maskHR, predPatchHR)\n",
    "\n",
    "    testLoss(loss)\n",
    "    testPSNR(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftCompensatedcPSNR(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The maximum cPSNR of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    N, H, W, C = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = H - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = W - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cachecPSNR = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "            stackcPSNR(i, j, patchHR, maskHR, cropPrediction, cachecPSNR)\n",
    "    cachecPSNR = tf.stack(cachecPSNR)\n",
    "    maxcPSNR = tf.reduce_max(cachecPSNR)\n",
    "    return maxcPSNR\n",
    "\n",
    "\n",
    "\n",
    "def shiftCompensatedL2Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The minimum L2 Loss of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    N, H, W, C = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = H - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = W - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cacheLosses = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "            stackL2Loss(i, j, patchHR, maskHR, cropPrediction, cacheLosses)\n",
    "    cacheLosses = tf.stack(cacheLosses)\n",
    "    minLoss = tf.reduce_min(cacheLosses)\n",
    "    return minLoss\n",
    "\n",
    "\n",
    "def shiftCompensatedL1Loss(patchHR: tf.Tensor, maskHR: tf.Tensor, predPatchHR: tf.Tensor) -> float:\n",
    "    '''\n",
    "    The minimum L1 Loss of every possible pixel shift between the predicted HR image and the ground truth.\n",
    "    This is how the ESA has been computing the submissions of the contestants.\n",
    "    See details at the ff link: https://kelvins.esa.int/proba-v-super-resolution/scoring/\n",
    "    '''\n",
    "    N, H, W, C = tf.shape(patchHR)\n",
    "\n",
    "    cropSizeHeight = H - MAX_PIXEL_SHIFT\n",
    "    cropSizeWidth = W - MAX_PIXEL_SHIFT\n",
    "    cropPrediction = cropImage(predPatchHR, CROP_BORDER, cropSizeHeight, CROP_BORDER, cropSizeWidth)\n",
    "    cacheLosses = []\n",
    "\n",
    "    # Iterate through all possible shift configurations\n",
    "    for i in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "        for j in tf.range(MAX_PIXEL_SHIFT+1):\n",
    "            stackL1Loss(i, j, patchHR, maskHR, cropPrediction, cacheLosses)\n",
    "    cacheLosses = tf.stack(cacheLosses)\n",
    "    minLoss = tf.reduce_min(cacheLosses)\n",
    "    return minLoss\n",
    "\n",
    "\n",
    "def stackL1Loss(i: int, j: int, patchHR: tf.Tensor, maskHR: tf.Tensor, cropPred: tf.Tensor, cache: List[float]):\n",
    "    N, cropSizeHeight, cropSizeWidth, C = tf.shape(cropPred)\n",
    "    cropTrueImg = cropImage(patchHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropTrueMsk = cropImage(maskHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropPredMskd = cropPred * cropTrueMsk\n",
    "    totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "    b = computeBiasBrightness(totalClearPixels, cropTrueImg, cropPredMskd)\n",
    "\n",
    "    correctedCropPred = cropPred + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    L1Loss = computeL1Loss(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cache.append(L1Loss)\n",
    "\n",
    "\n",
    "\n",
    "def stackL2Loss(i: int, j: int, patchHR: tf.Tensor, maskHR: tf.Tensor, cropPred: tf.Tensor, cache: List[float]):\n",
    "    N, cropSizeHeight, cropSizeWidth, C = tf.shape(cropPred)\n",
    "    cropTrueImg = cropImage(patchHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropTrueMsk = cropImage(maskHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropPredMskd = cropPred * cropTrueMsk\n",
    "    totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "    b = computeBiasBrightness(totalClearPixels, cropTrueImg, cropPredMskd)\n",
    "\n",
    "    correctedCropPred = cropPred + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    L2Loss = computeL2Loss(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cache.append(L2Loss)\n",
    "\n",
    "\n",
    "def stackcPSNR(i: int, j: int, patchHR: tf.Tensor, maskHR: tf.Tensor, cropPred: tf.Tensor, cache: List[float]):\n",
    "    N, cropSizeHeight, cropSizeWidth, C = tf.shape(cropPred)\n",
    "    cropTrueImg = cropImage(patchHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropTrueMsk = cropImage(maskHR, i, cropSizeHeight, j, cropSizeWidth)\n",
    "    cropPredMskd = cropPred * cropTrueMsk\n",
    "    totalClearPixels = tf.reduce_sum(cropTrueMsk, axis=(1, 2, 3))\n",
    "\n",
    "    b = computeBiasBrightness(totalClearPixels, cropTrueImg, cropPredMskd)\n",
    "\n",
    "    correctedCropPred = cropPred + b\n",
    "    correctedCropPredMskd = correctedCropPred * cropTrueMsk\n",
    "\n",
    "    cPSNR = computecPSNR(totalClearPixels, cropTrueImg, correctedCropPredMskd)\n",
    "    cache.append(cPSNR)\n",
    "\n",
    "\n",
    "def computeL1Loss(totalClearPixels, HR, correctedSR):\n",
    "    loss = (1.0 / totalClearPixels) * tf.reduce_sum(tf.abs(tf.subtract(HR, correctedSR)), axis=(1, 2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def computeL2Loss(totalClearPixels, HR, correctedSR):\n",
    "    loss = (1.0 / totalClearPixels) * tf.reduce_sum(tf.square(tf.subtract(HR, correctedSR)), axis=(1, 2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def computecPSNR(totalClearPixels, HR, correctedSR):\n",
    "    loss = (1.0 / totalClearPixels) * tf.reduce_sum(tf.square(tf.subtract(HR, correctedSR)), axis=(1, 2))\n",
    "    cPSNR = -tf.math.log(loss) / tf.math.log(tf.constant(10, dtype=tf.float32))\n",
    "    return cPSNR\n",
    "\n",
    "\n",
    "def computeBiasBrightness(totalClearPixels, HR, SR):\n",
    "    N, H, W, C = tf.shape(HR)\n",
    "    b = (1.0 / totalClearPixels) * tf.reduce_sum(tf.subtract(HR, SR), axis=(1, 2, 3))\n",
    "    b = tf.reshape(b, (N, 1, 1, C))\n",
    "    return b\n",
    "\n",
    "\n",
    "def cropImage(imgBatch: tf.Tensor, startIdxH: int, lengthHeight: int,\n",
    "              startIdxW: int, lengthWidth: int) -> tf.Tensor:\n",
    "    return tf.cast(imgBatch[:, startIdxH: startIdxH + lengthHeight, startIdxW: startIdxW + lengthWidth, :], tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
